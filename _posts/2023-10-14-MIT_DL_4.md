---
title: 4.Numerical Computation [Deep Learning-MITpress 번역본]
author: onebom
date: 2023-10-14 00:00:00 +0800
categories: [DL]
tags: []
toc: true
---

ML알고리즘은 일반적으로 많은 computation을 필요로합니다.   
이는 일반적으로 정확한 해에 대한 기호식을 제공하기 위해 공식을 분석적으로 도출하는 것이 아니라 반복적인 과정을 통해 해의 추정치를 갱신하는 방법으로 수학적 문제를 해결하는 알고리즘을 말합니다. 일반적인 연산으로는 최적화(함수를 최소화 또는 최대화하는 인수의 값을 찾는것)와 연립 방정식을 푸는 것이 있습니다.    
디지털 컴퓨터에서 수학적 함수를 평가하는 것만으로도 함수에 실수가 포함된 경우에는 어려울 수 있다. 실수는 유한한 용량의 메모리를 사용하여 정확하게 표현할 수 없기때문입니다.

## 1. Overflow and Underflow
디지털 컴퓨터에서 countinous math를 수행할 때 근본적인 어려움은 유한한 수의 비트 패턴으로 무한히 많은 실수를 표현해야 한다는 것입니다. 이는 거의 모든 실수의 경우 컴퓨터에서 그 수를 나타낼 때 근사 오차가 발생한다는 것을 의미합니다.     
- 많은 경우 이는 단순한 반올림 오차에 불과합니다. 
- 반올림 오차는 특히 많은 연산에 걸쳐 복합적으로 작용할 때 문제가 되며 이론적으로 작동하는 알고리즘이 반올림 오차의 누적을 최소화하도록 설계되지 않은 경우 실제로 실패할 수 있습니다.

특히 치명적인 반올림 오차의 한 형태는 **underflow**입니다.    
언더플로우는 0에 가까운 숫자가 0으로 반올림될 때 발생합니다. 
- 많은 함수들은 인수가 작은 양수가 아니라 0일 때 질적으로 다르게 동작합니다. 
- 예를 들어, 우리는 보통 0으로 나눗셈하는 것을 피하기를 원합니다(어떤 소프트웨어 환경에서는 예외가 발생하면 자리 표시자가 아닌 값으로 결과를 반환하고), 다른 소프트웨어 환경에서는 0으로 로그를 취합니다(이것은 보통 - ∞로 취급되며, 이후 많은 산술 연산에 사용되면 숫자가 아닙니다). 

또 다른 매우 손상적인 형태의 수치 오차는 **overflow**입니다.    
오버플로는 크기가 큰 수를 ∞ 또는 -∞로 근사할 때 발생합니다.  
- 산술은 일반적으로 이러한 무한 값을 숫자가 아닌 값으로 변경합니다. 


언더플로우 및 오버플로우에 대해 안정화되어야 하는 함수의 한 예는 **softmax** 함수입니다. 
- softmax 함수는 종종 다중 서울 분포와 관련된 확률을 예측하기 위해 사용됩니다. softmax 함수는 다음과 같이 정의됩니다

$$softmax(x_i) = {exp(x_i) \over \sum_{j=1}^n exp(x_j)}$$

모든 xi가 어떤 상수 c와 같을 때 무슨 일이 일어나는지 생각해보세요.   
분석적으로 모든 출력이 1/n과 같아야 한다는 것을 알 수 있습니다. 
- 수치적으로 c가 큰 크기일 때는 이런 일이 일어나지 않을 수 있습니다. 
- c가 매우 음수이면 exp(c)는 밑으로 흐릅니다.    
  이것은 소프트맥스의 분모가 0이 된다는 것을 의미하므로 최종 결과는 정의되지 않습니다.
- c가 매우 크고 양수이면 exp(c)가 넘쳐서 식 전체가 정의되지 않습니다. 

이 두 가지 어려움은 대신 $$z = x - max_{i}x_i$$인 $$softmax(z)$$를 계산하면 해결할 수 있습니다. 단순 대수학은 입력 벡터에서 스칼라를 더하거나 뺄 때 소프트맥스 함수의 값이 분석적으로 변하지 않음을 보여줍니다. 
- $$max_{i}x_i$$ 빼면 exp에 대한 가장 큰 인수가 0이되어 오버플로우의 가능성이 배제됩니다. 
- 마찬가지로, 분모의 적어도 하나의 항은 1의 값을 갖는데, 이것은 분모에서 0으로 나눗셈에 이르게 하는 언더플로우의 가능성을 배제합니다. 

여전히 한 가지 작은 문제가 있습니다. 분자 내 언더플로우는 여전히 식을 전체적으로 0으로 평가하게 할 수 있습니다. 이것은 softmax 서브루틴을 먼저 실행한 후 결과를 로그 함수에 전달하여 로그 softmax(x)를 구현할 경우 - ∞를 잘못 얻을 수 있음을 의미합니다. 대신에 로그 softmax를 수치적으로 안정적인 방법으로 계산하는 별도의 함수를 구현해야 합니다. softmax 함수를 안정화할 때와 같은 방법으로 로그 softmax 함수를 안정화할 수 있습니다. 

우리는 대부분 이 책에서 설명한 다양한 알고리즘을 구현할 때 관련된 모든 수치적 고려 사항을 명시적으로 상술하지는 않습니다. 하위 수준 라이브러리 개발자는 딥러닝 알고리즘을 구현할 때 수치적 문제를 염두에 두어야 합니다. 이 책의 대부분의 독자는 단순히 안정적인 구현을 제공하는 하위 수준 라이브러리에 의존할 수 있습니다. 경우에 따라 새로운 알고리즘을 구현하고 새로운 구현을 자동으로 안정화하는 것이 가능합니다. Theano(Bergstra et al., 2010; Bastien et al., 2012)는 딥러닝 맥락에서 발생하는 많은 일반적인 수치적으로 불안정한 표현을 자동으로 검출하고 안정화하는 소프트웨어 패키지의 한 예입니다.


## 2.  Poor Conditioning
Conditioning는 함수가 입력의 작은 변화에 대해 얼마나 빠르게 변화하는지를 말합니다. 입력이 약간 동요할 때 빠르게 변화하는 함수는 입력의 반올림 오류가 출력의 큰 변화를 초래할 수 있기 때문에 과학적 계산에 문제가 될 수 있습니다.
함수 f(x) = A-1x 를 생각해봅시다. A ∈ R_nxn 가 고유값 분해를 가질 때, 그 조건 번호는
$$\max_{i,j} \left|{\lambda_i \over \lambda_j }\right|$$

이것은 가장 큰 고유값과 가장 작은 고유값의 크기의 비율입니다.    
이 숫자가 크면 행렬의 반전은 입력의 오류에 특히 민감합니다.   
- 이 민감도는 행렬 자체의 고유한 성질이지 행렬 반전 시 반올림 오차의 결과가 아닙니다
조건이 나쁜 행렬은 실제 행렬을 역으로 곱할 때 기존의 오차를 증폭합니다. 실제로는 반전 과정 자체에서 수치 오차로 인해 오차가 더욱 증폭됩니다.

## 3. Gradient-Based Optimization
대부분의 딥 러닝 알고리즘은 일종의 최적화를 수반합니다. 최적화는 x를 변경함으로써 일부 함수 f(x)를 최소화하거나 최대화하는 작업을 말합니다. 우리는 보통 f(x)를 최소화한다는 관점에서 대부분의 최적화 문제를 표현합니다. 최대화는 -f(x)를 최소화함으로써 최소화 알고리즘을 통해 달성될 수 있습니다.   

최소화 또는 최대화하고자 하는 함수를 **objective function** 또는 **criterion**이라고 합니다. 최소화할 때 **cost function, loss function or error function**라고도 부를 수 있습니다. 이 책에서는 이 용어들을 서로 교환하여 사용하지만, 일부 기계 학습 간행물에서는 이 용어들에 특별한 의미를 부여합니다.
우리는 종종 위첨자 ∗로 함수를 최소화 또는 최대화하는 값을 나타냅니다.    
예를 들어 $$x^∗ = \argmin f(x)$$라고 말할 수 있습니다.

우리는 독자가 미적분학에 이미 익숙하다고 가정하지만, 미적분학 개념이 최적화와 어떻게 관련되는지에 대한 간단한 검토를 제공합니다.    
x와 y가 모두 실수인 함수 y = f(x)가 있다고 가정합시다. 이 함수의 도함수(derivative)는 $$f'(x)$$ 또는 $${dx \over dy}$$로 표시된다. 도함수 f'(x)는 점 x에서 f(x)의 기울기를 제공합니다.     
즉, 출력의 해당 변화를 얻기 위해 입력의 작은 변화를 조정하는 방법을 지정합니다: $$f(x+\epsilon) ≈ f(x) + \epsilon f'(x)$$ 

!(figure1)[../assets/img/posts/MIT_DL4/figure1.png]

따라서 도함수는 함수를 최소화하는 데 유용한데, 이는 y를 작게 개선하기 위해 x를 어떻게 바꾸는지 알려주기 때문입니다. 
- 예를 들어, 우리는 $$f(x-\epsilon sign(f'(x)))$$가 충분히 작은 $$\epsilon $$일 때 f(x)보다 작다는 것을 알고 있습니다.
- 따라서 도함수의 반대 부호를 가진 x를 작은 걸음으로 이동시킴으로써 f(x)를 줄입니다.  
이 기술은 **gradient descent**라고 불립니다

!(figure2)[../assets/img/posts/MIT_DL4/figure2.png]

- f'(x) = 0인 경우, 도함수는 어느 방향으로 이동할지에 대한 정보를 제공하지 않습니다. - f'(x) = 0인 점을 **critical points 또는 stationary points**이라고 합니다. **local minimum**은 f (x)가 이웃한 모든 점보다 낮은 점이므로, 더 이상 극솟값으로 f(x)를 감소시킬 수 없습니다. 
- **local maximum**은 f (x)가 이웃한 모든 점보다 높은 점이므로, infinitesimal steps를 수행하여 f (x)를 증가시킬 수는 없습니다. 
- 일부 임계점은 극대도 극솟값도 아닙니다. 이것을 **saddle points**이라고 합니다. 각

f(x)의 절대 최저값을 구하는 점은 **global minimum**입니다.    
- 함수의 전역 최소값이 하나이거나 여러 개일 수 있습니다. 
- 전역적으로 최적이 아닌 local minimum이 있을 수도 있습니다. 
딥 러닝의 맥락에서, 우리는 최적이 아닌 많은 local minimum과 매우 평평한 영역으로 둘러싸인 많은 saddle points을 가질 수 있는 함수를 최적화합니다.    
특히 함수에 대한 입력이 다차원인 경우 이 모든 것이 최적화를 매우 어렵게 만듭니다.따라서 우리는 보통 매우 낮지만 반드시 형식적인 의미에서 최소는 아닌 f 값을 찾는 것으로 만족합니다.

우리는 종종 여러 입력이 있는 함수를 최소화합니다: $$f : \mathbb{R}_n → \mathbb{R}$$.   
- "minimization"의 컨샙이 말이되려면 하나의 (scalar) 출력만이 있어야 합니다.    

다수의 입력을 가지는 함수에 대하여, 우리는 **partial derivatives**(편미분)의 개념을 사용해야 합니다. 편미분 $${ \partial \over \partial x_i}f(x)$$는 x지점에서 변수 x_i가 증가함에따라 f가 얼마나 변하는가를 측정합니다. **gradient**는 도함수가 벡터에 대해 존재하는 경웨 도함수의 개념을 일반화합니다: f의 기울기는 $${\nabla}_x f(x)$$로 표시되는 편미분을 포함하는 벡터입니다.
- 기울기의 element i는 x_i에 대한 편미분입니다.
- 다차원에서, critical points는 기울기가 0인 모든 element가 있는 곳을 가르킵니다.

unit vector인 u의 방향에서의 **directional derivative**(방향 도함수)은 함수 f의 기울기입니다. 즉, directional derivative는 $$\alpha=0$$라고 evaluated되는 $$\alpha$$에 대한 함수 $$f(x+\alpha u)$$의 도함수다. chain rule을 사용하면 $$\alpha=0$$일때, $${\partial \over \partial \alpha}f(x+\alpha u)$$는 $$u^T {\nabla}_x f(x)$$로 쓸 수 있다.

f를 최소화하기 위해서, f가 가장 빠르게 감소하는 방향을 찾을것입니다. 우리는 directional derivative를 사용하여 찾을 수 있습니다;

$${\min}_{u,u^{T}u=1} u^T {\nabla}_x f(x)$$

$$= {\min}_{u,u^{T}u=1} \left| u \right|^2 \left| {\nabla}_x f(x) \right|^2 \cos \theta$$

- θ는 u와 gradient간의 각도입니다.
- ||u||2 = 1로 치환하고 u에 의존하지 않는 인자를 무시하면, $${\min}_u \cos \theta$$로 간단화할 수 있습니다.
- 이것은 u가 gradient와 반대방향을 가리킬 때 최소화됩니다.
- 즉 gradient는 오르막을 가리키고, negative gradient는 내리막을 가리킵니다.
우리는 negative gradient로 이동함으로써 f를 줄일 수 있습니다. 이 방법은 **steepest descent or gradient descent**라 알려져 있습니다.

**steepest descent**는 새로운 지점을 제시합니다;
$$x'=x - \epsilon {\nabla}_x f(x)$$
- \epsilon은 **learning rate**라 하며, step size를 결정하는 positive scalar입니다.
- 우리는 \epsilon을 다양한 방법으로 고를 수 있습니다.
  1. 일반적인 접근법은 epsilon을 작은 상수로 설정하는 것입니다. 때떄로 directional derivative vanish를 일으키는 step size에 대해 해결할 수 도 있습니다.
  2. 다른 접근법은 여러 epsilon 값에 대해 $$f(x - \epsilon {\nabla}_x f(x))$$ 를 계산하고 가장 작은 목적함수값을 선택하는 것입니다. 이 방식을 **line search**라고 합니다.

Steepest descent는 기울기의 모든 원소가 0일때(또는 실제로 0에 매우 가까울때) 수렴합니다. 어떤 경우에는, 반복 알고리즘을 실행하는 것을 피하고 x에 대한 $${\nabla}_x f(x)=0$$을 풀어내면 critical point를 바로 알아낼 수 있습니다.   

gradient descent는 continuous spaces에서의 최적화로 제한되지만, 더 나은 configurations을 향해 반복적으로 작은 움직임을 하는 일반적 개념의 discrete spaces으로 일반화할 수 있습니다.   
discrete 매개변수들의 목적함수를 상승시키는 것을 **hill climbing**이라고 합니다.

### 1) Beyond the Gradient: Jacobian and Hessian Matrices


2. Constrained Optimization
3. EX) Linear Least Squares



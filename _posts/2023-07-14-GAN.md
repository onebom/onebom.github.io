---
title: GAN 톺아보기(GAN, DCGAN, WGAN)
author: onebom
date: 2023-07-14 20:55:00 +0800
categories: [DL, ComputerVision]
tags: [GAN]
toc: true
---

## What is GAN(Generative Adversarial Network)?

### [Summary]
생성모델G와 판별모델D의 상호 경쟁과정을 통해 이미지 feature 분포를 학습하여 학습 데이터의 평균양상을 띄는 이미지를 생성할수 있도록하는 학습 프레임워크이다.
- Generative model(생성모델G) : *captures the data distribution*, 학습 데이터의 분포와 근사한 데이터 생성
- Discriminative model(판별모델D) : G에서 생성된 가짜 데이터와 학습하는 진짜 데이터를 분류

결과적으로 G모델이 학습데이터의 분포를 묘사할 수 있게되면, D모델은 실제 학습데이터인지 G가 생성한 가짜 데이터인지 맞출 확률은 1/2에 수렴한다.   
즉, 잘 학습되어진 D가 G로부터 생성된 데이터를 가짜라고 판별하지 못하게 하는 것이 목적인 샘이다.   

논문 저자인 lan Goodfellow가 본문에서 든 예시는 지폐위조범과 경찰이다;
> 지폐위조범은 경찰을 열심히 속이려고 하고, 경찰은 위조된 지폐를 진짜와 감별하려고 노력한다.
> 이런 경쟁 속에서 두 그룹을 모두 속이고 구별하는 서로의 능력이 발전하게 되면,    
> 결과적으로 진짜 지폐와 위조 지폐를 구별할 수 없는 정도(구별할 확률 $p_d=0.5$)에 이른다. 

### Adversarial Nets
D의 입장에서는 data로부터 뽑은 sample x는 D(x)=1이 되고, G에 임의의 noise distribution으로부터 뽑은 input z를 넣고 만든 sample에 대해서는 D(G(z))=0이 되도록 노력한다.    
즉, D는 실수할 확률을 낮추기 위해 노력하고(mini), G는 D가 실수할 확률을 높이기 위해 노력하기(max) 때문에 논문에선 둘을 같이 놓고 **minimax two-player game**이라 표현한다.    

![figure1](/assets/img/posts/GAN/figure1.png)
- 첫째항: real data x를 Discriminator에 넣었을 때 나오는 결과를 log 취해서 얻는 값
- 두번째 항: fake data z를 generator에 넣어서 나온 sample을 Discriminator에 넣어 log 취해서 얻는 값

1. D의 입장: D의 판별 성능이 뛰어나다고 보장되었을 때, sample이 실제 데이터라면 D(x)=1이 되어 첫째항 log값은 0으로 사라진다. 두번째 항에서는, 생성된 이미지를 가짜라고 잘 판별할 것이기 때문에, D(G(z))=1이 되어 두번째 항 역시 0이 되며 결과적으로 V(D,G)=0이 된다. 
   - D의 입장에서 얻을수 있는 'max'는 결과적으로 loss 0을 출력한다.
   - 'max': D가 올바르게 라벨을 분류할 확률을 최대화 하는 것
2. G의 입장: G가 D를 속일수 있는 이미지를 생성했을 경우, D(G(z))=1이므로 두번쨰 행은 log0이되어 마이너스 무한대로 간다. 
   - G의 입장에서 얻을 수 있는 'min'은 결과적으로 loss에 대해 -무한대를 출력한다.
   - 'min': log(1-D(G(z))) 즉, D가 생성된 이미지의 라벨을 올바르게 분류 확률을 최소화 시키는 것

> [주의] 
> 학습에서 D를 최적화하는 데에는 많은 계산들을 필요로 하며, 적은 데이터셋에서는 overfitting을 초래하기도 한다.
> 따라서 **k step 만큼 D를 최적화한 후 G는 1 step 만큼만 최적화한다.**
> - 학습 초반에는 G의 성능이 형편없기 때문에, D가 G가 생성한 데이터와 실제 데이터를 너무 잘 구별한다. 
> - 이 경우에, log(1-D(G(z)))는 포화상태가 되기 때문에(즉, gradient가 너무 작은 값이 나와 학습이 느리기 때문에) 
> - **log(1-D(G(z)))를 최소화하기 보다 log(D(G(z)))를 최대화**하게끔 학습하는 것이 좋다.

![figure2](/assets/img/posts/GAN/figure2.png)
- 검정색: 실제 데이터 distribution(real), 파란색: D distribution, 초록색: G distribution(fake)
위의 figure는 시간에 따른 학습 분포를 나타냈다.
1. a) real과 fake의 분포가 전혀 다르고, D의 성능도 좋지 않음
2. b) D가 real과 fake를 분명하게 판별
3. c) D의 학습이 어느정도 이뤄지면, G는 real 데이터 분포를 따라가며 D가 구별해내기 어려운 데이터를 생성하도록 학습함
4. d) real과 fake의 분포가 거의 비슷해져 구분할 수 없을 만큼 G가 학습하고, D는 결국 둘을 구분할 수 없어 1/2로 수렴한다.

## DCGAN
GAN은 데이터분포의 학습에 있어서 Markov Chain 없이, back-porpagation을 통한 추론으로 배울수 있다는 것이 핵심적이었다.    
그러나 학습에 있어서 D,G의 균형을 잘 맞추기 힘들다는 구조적 불안정함이 단점이었다.

따라서 Convolutional 구조를 GAN에 녹여 구조를 안정화하고자 한것이 DCGAN이다.
DCGAN의 출현으로 아래와 같은 기여를 할수 있었다;
1. 대부분의 상황에서 안정적으로 학습이 가능한 GAN 구조를 찾아낸 점
2. Generator가 벡터산술 연산이 가능하다는 점
3. 특징 filter들이 이미지의 특정 물체를 학습할 수 있었다는 점

### Model Architecture
논문에서는 모델을 어떤식으로 짜야하는지 guide line이 명시되어 있어 그대로 들고 왔다.   
![figure3](/assets/img/posts/GAN/figure3.png)
1. 모든 pooling layer를 D에서는 strided convolution으로, G에서는 fractional-strided convolution으로 대체하라.
2. G와 D 모두에 batch normalization을 추가하라
3. fully connected layer를 모두 제거해라
4. G에서 ReLU activation을 output을 제외한 모든 layer에서 사용하고, output layer는 Tanh를 사용해라
5. D에서는 모든 layer에 Leaky ReLU activation을 사용해라

결과적으로, DCGAN의 Generator 구조는 다음과 같다;   
![figure4](/assets/img/posts/GAN/figure4.png)

### latent Z vector
기존의 word2vec에서 "왕-남자+여자=여왕"과 같은 언어 연산이 가능하다. 이런 연산은 단어의 의미를 이해하고 그에 맞는 새로운 다어를 찾아야하는 고차원 처리가 필요한 문제이다. DCGAN에서는 이러한 연산을 이미지에서도 가능하다는 것을 보였다.    

![figure5](/assets/img/posts/GAN/figure5.png)
z중에 "안경+남자"를 그리게 하는 입력값들을 모아 평균치를 구하고, '안경x 남자"와 "안경x 여자"의 입력값에 대해서도 평균치를 구한 후 각각을 뺴고 더해주면 새로운 z가 출력된다. 새로운 z를 GAN에 넣어 결과 이미지를 받으면 "안경+여자"가 나온다.
input z는 단순 Gaussian noise이기 때문에, 결과 이미지의 품질은 z에 의해서가 아닌 generator의 z를 mapping하는 함수의 역할이다. 따라서 해당 네트워크는 학습데이터를 단순히 암기해서 생성한 것이 아니라는 것이 증명된다. 아래 예시를 보면 더 와닿을 것이다.   
![figure6](/assets/img/posts/GAN/figure6.png)
왼쪽을 보고 있는 얼굴을 만들어내는 input zleft들의 평균 vector z¯left과 오른쪽을 보고 있는 얼굴에 대응하는 zright들의 평균 vector z¯right를 계산하고 이 두 벡터의 사이를 잇는 축(axis)을 interpolating하여 Generator에 넣어보았더니 천천히 "회전(turn)"하는 얼굴들이 나오는 것을 볼 수 있다.

## WGAN


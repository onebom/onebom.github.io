---
title: 끄적이며 정리하는 Diffusion Model
author: onebom
date: 2024-02-27 00:00:00 +0800
categories: []
tags: []
toc: true
published: true
math: true
---

## 1. What is a Diffusion Model
diffusion model의 시작은 논문 abstarct에 쓰여있듯이 non-equilibrium thermodynamics이다. 
[권민기님](https://www.youtube.com/watch?v=uFoGaIVHfoE&list=PLMt_iGrhm2UvSXBM7SmngPB9gtMQpy-CN&index=1)의 physical intuition 설명에따르면,   
> 분자에 diffusion을 가하게 되면, 본래 분자모임의 struct가 망가진다. 지속해서 diffusion이 가해져 시간이 지나면, 결국 분자는 공간에 uniform하게 분포되게 될것이다. 따라서 우리가 잘 알고있는 uniform에서 시작해 처음 상태로 돌아갈 수 있다면, diffusion이 가해지기 전 최초의 분자 상태를 알아낼 수 있다. 이를 딥러닝으로 해결하고자 한것이다.    
![figure0](/assets/img/posts/ddpm/figure0.gif) 
- 열역학에서 분자들의 다음 위치는 가우시안 분포 안에서 결정된다.
- 또한, 정말 작은 sequence에서 diffusion은 foward와 reverse 모두 가우시안이다. ????

diffusion model은 Markov chain에 기반하여 데이터에 random noise를 천천히 추가하는 diffusion 단계를 정의하고, 완전 노이즈로부터 원하는 데이터 샘플을 구성하는 diffusion reverse 단계를 학습한다.   

다른 생성모델과 달리, latent variable이 원본데이터와 동일한 높은 dimensionality를 가진다.
![figure1](/assets/img/posts/ddpm/figure1.png)

!! diffusion model vs ddpm 간단하게

DDPM paper Abstarct의 아래 두줄에 집중해서 본 post를 읽어볼 것이다. 
> diffusion probabilistic model과 denoising score matching with Langevin dtnamics를 연결한 weighted variational bound를 통해 좋은 학습결과를 냈다.
> 또한, autoregressive deocding을 일반화한 progressive lossy decompression scheme을 제안한다.
워낙 생소한 단어로 abstract에서 모델을 설명하고 있기에, 이를 간단하게 설명하고자 한다.   
따라서 본 글을 읽을땐, 아래의 질문3개를 기억하며 읽어주길 바란다.
<details>
<summary>**[QnA]**</summary>
<div markdown="1">
1. **비평형 열역학과 DDPM의 공통점은?** : 
    작은 time sequence에서 diffusion의 foward와 reverse가 모두 가우시안이라는 점을 사용하여, 비평혁 열역학이 uniform한 분자분포에서 diffusion 이전의 본래 분자 상태를 알아내듯이 diffusion model도 마찬가지로 데이터에 gaussian noise를 가하는 foward process의 역을 알아내 gaussian noise가 주어졌을 때 원본 데이터를 구한다.
2. **weithted variational bound가 무엇을 말하는 지** :
3. **progressive lossy decompression이 어떻게 일어나는지** :
</div>
</details>

## 2. How does it work?

> A diffusion probabilistic model(which we will call a “diffusion model” for brevity) is a parameterized Markov chain trained using variational inference to produce samples matching the data after finite time

### (1) Foward diffusion process
먼저, 데이터에 노이즈를 더해가며 완전 gaussian distribution의 lantent variable을 만들어내는 foward process에 대해 알아보자.   

![figure3](/assets/img/posts/ddpm/figure3.PNG)
실제 데이터 분포에서 샘플링한 data point $x_0 \sim q(x)$가 주어졌을 때, 해당 샘플에 T스텝만큼 소량의 Gaussian noise를 추가하며 $x_1,...,x_T$ noisy smaples sequence를 얻는다.
- 이때 각 step의 size는 variance schdule에 의해 0에서 1사이로 조정된다: ${\beta_{t} \in (0,1)}^{T}_{t=1}$

data sample x_0은 점진적으로 t가 커짐에 따라 diftinguishable features들을 잃는다. 결과적으로 T가 무한에 수렴하게 되면 x_T는 완전 Gaussian distribution을 따르게 된다.   
**x_{t-1}로부터 노이즈를 더해 x_t를 구하는 과정**을 식으로 표현하면 다음과 같다;   

$$q(x_t|x_{t-1})=N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_{t}\mathbf{I}) \rightarrow q(x_{1:T}|x_0)=\prod_{t=1}^T q(x_t|x_{t-1}) $$

- x_t를 정의할때 x_{t-1}을 사용한 조건부확률분포로 표현할 수 있고, x_t는 정규분포를 따른다.(왜?????)
- 정규분포항을 살펴보면 x_t의 평균이 x_{t-1}에 비례하되, 1-beta_t가 곱함으로써 이전상태의 영향을 감소시켰다. 대신, 분산에 beta_t를 둠으로써 beta_t 값에 따라 노이즈를 더한다.
    - 뒤에서 설명하겠지만, beta_t 매개변수는 시간에 따라 값이 변동하도록 설정해둔다.
    <details>
    <summary>varaince 관점에서 x_t의 정규분포</summary>
    <div markdown="1">
    왜 x_t가 저런 정규분포 식을 갖는지 궁금할 것이다. 안 궁금하면 넘어가도된다.    
    결과부터 말하면, Variance를 1로 유지하기 위함이다.    

    분산의 누적과정을 추적해보자. x_t의 분산은 다음과 같이 표현될 수 있다;

    $$Var(x_t) = Var(\sqrt{1-\beta_{t}} x_{t-1} + \epsilon_{t})$$

    - 여기서 epsilon은 평균이 0이고 분산이 beta_t인 정규분포에서의 노이즈를 나타낸다. 

    마저 전개하면,

    $$Var(x_t)=(\sqrt{1-\beta_{t}})^2 Var(x_{t-1})+ Var(\epsilon_{t})$$
    $$Var(x_t)=(1-\beta_{t})Var(x_{t-1})+\beta_t$$

    t-1에서의 분산이 1이라고 가정한다면, 식을 다음과 같이 간단하게 만들수 있다;

    $$Var(x_t)=(1-\beta_{t}) + \beta_{t} = 1$$

    위와 같은 조건하에, 다음 step으로 넘어가도 분산이 1로 일정하게 유지할 수 있다.

    </div>
    </details>

우항에 대해 살펴보면, Markov chain에 따라 $q(x_{1:T}|x_0)$는 T시점까지 $q(x_t \| x_{t-1})$의 joint distribution으로 나타낼 수 있다.
![figure8](/assets/img/posts/ddpm/figure8.jpg)



#### Diffusion Kernel
지금까지, diffusion forward process가 원본데이터에 noise를 조금씩 여러 step에 더해나가며 완전한 gaussian noise을 만든다는 개념에 대해 이해했다. 그렇다면, noise를 조금씩 단계별로 주는것 대신 **특정 time step에 대해 noise를 한번에 줄 수 있지 않을까?**   
foward diffusion process는 각 step에 대해 가우시안 커널들이 연속적으로 이뤄지기 때문에, 특정 step t에 대한 가우시안 커널을 한번에 정의할 수 있다. 그리고 이것이 기존의 diffusion model과 달리 ddpm이 가지는 특징이다.
![figure4](/assets/img/posts/ddpm/figure4.PNG)

해당 내용에 대해 paper에 아래와 같이 적혀있다.
> 이 process의 장점은 reparameterization trick을 사용하여, 임의의 시간 step t에 대해 *닫혀있도록* x_t를 sampling할 수 있어, explicit한 데이터 표현이 가능하다.   

이 문장에 대해 분석해보면, 임의의 시간 step t에 대해 x_t가 닫혀있도록 sampling한다는 표현은, 어떠한 시간 단계 t에서도 x_t를 직접얻어낼 수 있다는 말이다.   
즉, 중간 단계의 샘플링이 없어도 x_t 값을 계산할 수 있다는 것인데, 이것은 reparameterization trick으로 x_t의 노이즈항을 재매개변수화했기 때문이다.   

다시 쉽게 설명하자면, **기존의 x_t 식에 포함되어 있던 미분이 불가능한 노이즈 항을 N(0,I)에서 샘플링하도록 정의함으로써 t까지의 (1-beta) 값들의 누적곱으로 재매개변수화하여 미분 가능한 연산으로 변환했기 때문에 어떠한 t에 대해서도 x_t를 직접 구할 수 있다**라는 뜻이다.   

<details>
<summary>식전개로 reparameterization 과정을 쉽게 알아보자</summary>
<div markdown="1">
기존의 x_t 식은 $N(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_{t}\mathbf{I})$ 정규분포를 따르기 때문에 다음과 같이 쓸수 있다;

$$x_t=\sqrt{1-\beta_t}x_{t-1}+\beta_{t}\epsilon$$
- epsilon은 N(0,I)를 따르는 노이즈항이다.

여기서, 우리는 시점 t에 대해서 t 이전 step의 beta를 모두 product한 항을 정의하여 사용할 것이다;

$\alpha_{t}=1-\beta_{t}$ and $\bar{\alpha_{t}}=\prod_{i=1}^t \alpha_{i}$

위의 alpha 값을 사용해 기존의 x_t 식을 치환한다면,

$x_t = \sqrt{\alpha_{t}}x_{t-1}+\sqrt{1-\alpha_{t}}\epsilon_{t-1}$

이때 x_{t-1}은 x_{t-2},..., x_1은 x_0으로 표현될 수 있기 때문에, 차례차례 전개할 수 있다.


$= \sqrt{\alpha_{t}\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha{t}\alpha{t-1}}\bar{\epsilon}_{t-2}$

$= ... $

$= \sqrt{\bar{\alpha_{t}}}x_0 + \sqrt{1-\bar{\alpha_{t}}}\epsilon $

결과적으로 x_0이 주어졌을 때, $q(x_t \| x_0)$은 다음과 같이 가우시안으로 나타낼 수 있다

$$q(x_t \| x_0)= N(x_t; \sqrt{\bar{\alpha_{t}}}x_0, (1-\bar{\alpha_{t}})\mathbf{I})$$

</div>
</details>     

<br>

$$q(x_t \| x_0)= N(x_t; \sqrt{\bar{\alpha_{t}}}x_0, (1-\bar{\alpha_{t}})\mathbf{I})$$
- 이때 beta값은 T에 가까워질 수록 값이 커지도록 설정한다. 따라서, x_0에서 x_T에 가까워질 수록 이전 스텝에서 노이즈를 추가하는 비율이 커지게된다.

결과적으로, x_0만 있다면 어떤 임의의 t든간에 noise낀 x_t를 구해낼 수 있게 되었고 이를 통해 기존의 좋지않았던 diffusion model의 학습 성능을 높이게 되면서 DDPM 이후 diffusion model을 본격적으로 사용하기 시작했다.   
학습 성능을 높일 수 있던 이유에 대해서는 !!!!!!에서 설명하겠다.   


지금까지, 우리는 diffusion kerenl $$q(x_t|x_0)$$에 대해 알아보았다. diffusion kernel을 통해 q(x_t)를 이해할 수 있다.
![figure6](/assets/img/posts/ddpm/figure6.PNG)
- 위 figure에도 나와있듯이, q(x_t)는 q(x_0)과q(x_t)의 joint distribution으로 나타낼 수 있으며, q(x_0)에 gaussian convolution을 곱한거와 같다.


다른 기존의 diffusion model은 모델을 학습시킬때 x_0으로부터 전체 x_1~x_T의 diffusion 정보를 담은 해당 posteriror $$q(x_{1:T}|x_0)$$에 reverse diffusion process를 근사시키는 것이 목표였다.   
!! DDPM에서는 어떻게 하는가
![figure2](/assets/img/posts/ddpm/figure2.png)
- 즉, 노이즈로부터 데이터를 생성하는 $$q(x_{t-1}\|x_t)$$을 알아내기 위해, $$q(x_t\|x_{t-1})$$을 알고있으므로 모델 $$p_\theta(x_{t-1}\|x_t)$$를 $$q(x_t\|x_{t-1})$$에 근사시키는 방법이다.
- p를 q에 근사함으로써, $$q(x_{t-1}\|x_t)$$을 알아낼 수 있는 이유는 $$\beta_{t}$$가 아주 작은 size라면, 둘은 동일시 되기 때문이다. => 위에서 언급한 비평형 열역학의 특징 : "작은 time sequence에서 diffusion의 foward와 reverse가 모두 가우시안이라는 점" 


### (2) Reverse diffusion process
결과적으로, gaussian noise input으로 실제 샘플 $$x_t \sim~ N(0,I)$$를 다시 생성하는 과정을 reverse diffusion process라 하며, diffusion 과정이 작은 time sequence로 이뤄져있다고 가정했을때 reverse process를 gaussian으로 모델링할 수 있게 되어 해당 과정을 딥러닝 모델이 학습하도록 할 수 있다.   
![figure7](/assets/img/posts/ddpm/figure7.PNG)

diffusion kernel$$q(x_t\|x_{t-1})$$의 역을 근사하기 위한 모델 $$p_\theta(x_{t-1}\|x_t)$$는 가우시안 정규분포를 따른다고 가정해뒀기 때문에, 평균 \mu와 분산 \sigma만 안다면 데이터 분포를 추정할 수 있게되고 따라서 두 파라미터를 딥러닝 모델은 학습해야한다.

결론부터 말하면, DDPM의 가우시안 노이즈로부터 데이터를 생성하는 variational autoencoder를 학습시키는 과정은 아래의 negeative log likelihood에서의 variational upper bound를 최적화하는 과정이다;

$$\mathbb{E}_{q(x_0)} \left[ - \log p_{\theta}(x_0) \right] \leq \mathbb{E}_{q(x_0)q(x_{1:T}|x_0)} \left[ - \log \frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)} \right] =: L$$

먼말인지 하나도 몰라도 되고, 수식은 흐린눈으로 봐도 된다.   
지금부터 차근차근 설명해주겠다.   

우선, 잘알고 있는 bayes's rule을 통해 negative log likelihood에 대해서 집고넘어가자
<details>
<summary>알고있는 개념이라면 넘어가도 된다.</summary>
<div markdown="1">
[likelihood And Bayes's Rule]
![figure10](/assets/img/posts/ddpm/figure10.png)

- H: hypothesis로 추정하고자 하는 값이다. => prior은 추정하려는 값의 확률분포를 말한다
- D: observation으로 관측된 데이터를 말한다. 예를 들어 training data가 될 수 있다. => evidence는 데이터 자체의 분포를 뜻한다.
- Posterior: observation이 주어졌을 때의 H의 분포이다.
- likelihood: H가 주어졌을 때(가정을 한 상태)에서의 데이터의 확률분포를 말한다.

좀더, 예시를 들어 직관적으로 설명한다면   
![figure11](/assets/img/posts/ddpm/figure11.png)   
위와 같이 연속형 확률변수를 나타낼 때는 확률밀도함수 PDF로 표현한다.    
예시에서처럼, 고양이 몸무게 분포인 PDF는 고정되어 있고 4kg 이상 혹은 5kg 이상 처럼 입력데이터가 변할때의 해당 입력의 확률을 "Posterior"라고 한다.   
![figure12](/assets/img/posts/ddpm/figure12.png) 
위의 예시에선, 고양이 몸무게가 5kg로 고정되어있고 분포가 변하는 상황이며, 이때의 입력의 확률을 "likelihood"라 한다. 따라서, 입력이 주어졌을때 분포가 데이터를 얼마나 잘 설명하는가에 대한 지표가 된다. => 데이터들이 주어졌을때, 데이터를 가장 잘 설명할 수 있는 분포를 찾는 것인 딥러닝의 목적과 동일하다.


딥러닝의 관점에서 이해하자면,   
![figure13](/assets/img/posts/ddpm/figure13.PNG) 
mnist데이터 중 1이 그려진 이미지는 위와 같은 posterior값을 가진다. 이후 딥러닝 모델을 구현하여 class 확률값을 뽑았을때 아래의 분포들 중 정답과 가까운 분포는 model C의 distribution이다.    
![figure14](/assets/img/posts/ddpm/figure14.PNG) 
즉, likelihood가 가장 높은 분포다.

따라서 딥러닝 모델은 분포를 잘 학습해서 입력값들의 likelihood를 최대화시키는것이 목적이다. 이것이 바로 Maximum log likelihood estimation(MLE)이다.   

[Negative Log-liklihood]   
딥러닝을 잘 학습시키기 위해서는 모든 입력값에 대한 likelihood의 결합을 최대화하면 되고 목적함수는 다음과 같다;
$$ \arg \max_\theta f(x\|\theta) = \arg \max_\theta \{f(x\|\theta_{1}) \cdot f(x\|\theta_{1}) \cdots f(x\|\theta_{n}) \} $$ 

여기서, likelihood function은 다음과 같이 표현한다;

$ L(\theta) = p_\theta(x) = f(x\|\theta_{1}) \dot f(x\|\theta_{1}) \cdots f(x\|\theta_{n})$
$ = \prod_{i=1}^n f(x\|\theta_{n}) $

이때 likelihood function은 곱셈의 형태이다. 곱셈으로 이뤄진 복잡한 형태를 **덧셈으로 바꿔주기 위해 log를 취하게된다**

$log L(\theta) = p_\theta(x) = log \prod_{i=1}^n f(x\|\theta_{n}) = \sum_{i=1}^n log f(x\|\theta_{i}) $

이를, Log-likelihood라 한다.    
곱셈의 형태에서 덧셈으로 바꿨을 때 이점들은 [이분의 블로그](https://blog.naver.com/PostView.naver?blogId=ycpiglet&logNo=223110695364)를 확인해주길 바란다.   

마지막으로, 목적함수 값이 작아질 수록 좋은 딥러닝의 경사하강법을 사용하기위해 log-likelihood에 음수를 곱해주어 maximum 문제를 minimum문제로 바꾼다.

</div>
</details>


확률분포를 추정하는 모델은 입력데이터의 negative log-likelihood(NLL)를 최소화함으로써 학습을 최적화할 수 있다. 따라서, reverse diffusion process의 모델은 각 step에서의 generation에 필요한 모든 observation인 x_1~x_T에 대해 NLL을 최소화해야한다.   

low-dimension의 latent space(z)로부터 high-dimension의 데이터 분포를 표현하는 VAE 종류의 모델이 likelihood를 최적화하기 위해서는 두가지 step이 필요하다.
1. p_\theta(x)에 대해서 p(x_T) (latnet variable)를 marginalize하여 표현하는 것
    - latent variable의 확률밀도함수의 성질을 이용
2. p_\theta(x)에 대해서 p(x_T) (latnet variable)의 chain rule probability로 표현하는 것
    - Bayes Rule의 조건부 확률식을 이용
둘다 joint distribution이 사용될때, p_\theta(x)의 log-likelihood를 표현하는 방법이며 

#### p_\theta(x)에 대해 p(x_T)를 marginalize하여 표현하자


#### p(x)를 우리가 알고있는 gaussian noise인 p(x_T)의 chain rule로 표현하자
위의 figure를 보면 알수있듯이, reverse process를 표현하는 전체 식은 $$p_\theta(x_{0:T})$$며 foward와 마찬가지로 x_T에서 시작해서 $$p_\theta(x_{t-1}\|x_t)$$의 joint distribution으로 표현할 수 있다.   
![figure9](/assets/img/posts/ddpm/figure9.jpg)



### (3) Parameterization of Lt for Training loss
reverse diffusion process $$p_\theta(x_{t-1}|x_t)=N(x_{t-1};\mu_{\theta}(x_t,t),\sigma_{\theta}(x_t,t))$$를 조건부확률분포 $$q(x_{t-1}|x_t)$$를 근사하기 위해 모델을 학습시켜야한다.
따라서 $$\tilde{\mu_t}=\frac{1}{\root{\alpha_{t}}}(x_t - \frac{1-\alpha_{t}}{\root{1-\bar{\alpha_{t}}}}\epsilon_{t})$$를 예측하도록 \mu_\theta를 학습할 것이다.
x_t가 training 동안 input으로 들어갈 수 있기에, Gaussian noise 항을 reparameterize하여 time step t에서 x_t입력으로부터 epsilon_t(noise)를 예측할 수 있다.

Lt loss term은 \mu의 차이를 최소화하도록 학습된다.

parameterizing

noise schedule 

### (4) Training&Sampling Design and Network Architectures


## 3. Why does it work wll?
### Mathemetical Relationship with SDE and Score Matching

## 4. Advanced Fast Sampling: DDImplicitM


